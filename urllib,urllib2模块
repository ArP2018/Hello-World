python2里的
一. urllib模块知识点梳理
1. 使用urlopen方法发起页面请求
resp = urlopen(url, [data, [proxies]])
data: 页面参数，字典类型，使用urlencode()进行编码
proxies: 定义代理

调用urlopen方法返回对象的方法或者属性可以获得页面源代码，状态码，页面header等信息
resp.read()        # 返回页面源代码
resp.readline()    
resp.readlines()
resp.url 
resp.headers    
resp.code        # 返回状态码

2. POST与GET参数
GET的方式：拼接url
>>> import urllib
>>> params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})
>>> f = urllib.urlopen("http://www.musi-cal.com/cgi-bin/query?%s" % params)
>>> print f.read()

POST的方式：构造一个url参数，例子如下
>>> import urllib
>>> params = urllib.urlencode({'spam': 1, 'eggs': 2, 'bacon': 0})
>>> f = urllib.urlopen("http://www.musi-cal.com/cgi-bin/query", params)
>>> print f.read()

3. 使用代理
>>>proxies = {'http': 'http://www.someproxy.com:3128'}
方法一：
>>>filehandle = urllib.urlopen(some_url, proxies=proxies)
方法二：
>>> opener = urllib.FancyURLopener(proxies)
>>> f = opener.open("http://www.python.org")
>>> f.read()

4. 伪造浏览器
urllib 模块不能伪装你的User Agent字符串等（伪装浏览器）

5. 使用urlretrieve方法可以下载图片
urlretrieve(url, [filename])
url: 网络图片对应的url
filename: 保存保存路径

6. urllib模块的辅助方法
6.1 对url字符串进行编码
quote(), quote_plus()
>>> urllib.quote('http://www.baidu.com')
'http%3A//www.baidu.com'
>>> urllib.quote_plus('http://www.baidu.com')
'http%3A%2F%2Fwww.baidu.com'
6.2 对url进行解码
unquote(), unquote_plus()
>>>urllib.unquote('http://news.search.hexun.com/news?key=%B4%F3%C0%ED%B1%A6%D4%B6')
>>>'http://news.search.hexun.com/news?key=\xb4\xf3\xc0\xed\xb1\xa6\xd4\xb6'

二. python2里的urllib2模块
与urllib模块的区别：
a. urllib只可以发送url请求，urllib2可以设置请求header以达到伪造浏览器的目的
b. urllib2可以结合cookielib模块发送cookie
c. urllib包括urlencode方法，用来对字典类型的参数进行编码

urllib2模块的主要功能应用
1. 最简单的用法
1.1 使用urlopen
import urllib2
resp = urllib2.urlopen('http://www.baidu.com')
resp.read()

1.2 使用Request
import urllib2
req = urllib2.Request('http://www.baidu.com')       # 先定义一个请求对象，可以调用该对象的一些方法做处理，比如添加header，发送数据等操作
resp = urllib2.urlopen(req)
resp.read()

2. 发送数据
2.1 GET
import urllib
import urllib2
query_args = { 'q':'query string', 'foo':'bar' }
encoded_args = urllib.urlencode(query_args)
print 'Encoded:', encoded_args              # 'Encoded:q=query+string&foo=bar'
url = 'http://localhost:8080/?' + encoded_args
print urllib2.urlopen(url).read()
2.2 POST
import urllib
import urllib2

query_args = { 'q':'query string', 'foo':'bar' }
encoded_args = urllib.urlencode(query_args)
url = 'http://localhost:8080/'

2.2.1
print urllib2.urlopen(url, encoded_args).read()

2.2.2
request = urllib2.Request('http://localhost:8080/')
request.add_data(encoded_args)
print urllib2.urlopen(request).read()

3. 使用cookie
详见：《urllib2配合cookielib模拟登陆》

4. 伪造浏览器
import urllib2
request = urllib2.Request('http://localhost:8080/')
request.add_header('User-agent', 'PyMOTW (http://www.doughellmann.com/PyMOTW/)')
response = urllib2.urlopen(request)
data = response.read()
print data

5. 使用代理


三. python3里的改变
python3对模块进行了打包合并，主要的两个模块http和urllib，从3.3开始不再使用urllib2模块。
urllib按功能又包括了三个主要子模块
urllib.request, urllib.response, urllib.parse

1. 最简单的请求
>>> import urllib.request
>>> response = urllib.request.urlopen('https://www.baidu.com/')
>>> response
<http.client.HTTPResponse object at 0x000002603CF31860>
>>> response = urllib.request.urlopen('https://www.baidu.com/')
>>> response.url
'https://www.baidu.com/'
>>> response.headers
<http.client.HTTPMessage object at 0x000002603CF31C50>
>>> response.code
200
>>> print(response.headers)
Accept-Ranges: bytes
Cache-Control: no-cache
Content-Length: 227
Content-Type: text/html
Date: Tue, 30 Jan 2018 12:16:12 GMT
Last-Modified: Mon, 22 Jan 2018 07:46:00 GMT
P3p: CP=" OTI DSP COR IVA OUR IND COM "
Pragma: no-cache
Server: BWS/1.1
Set-Cookie: BD_NOT_HTTPS=1; path=/; Max-Age=300
Set-Cookie: BIDUPSID=D8F23F6387C70AA698797ED474452B16; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
Set-Cookie: PSTM=1517314572; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com
Strict-Transport-Security: max-age=0
X-Ua-Compatible: IE=Edge,chrome=1
Connection: close

2. 使用Request方法
>>> req = urllib.request.Request('http://www.baidu.com')
>>> resp = urllib.request.urlopen(req)
>>> resp.read()

3. POST方式发送数据
import urllib.request
import urllib.parse
d = urllib.parse.urlencode({'id':'A01', 'dbcode':'hgyd', 'wdcode':'zb','m':'getTree'}).encode('utf-8')
print(type(d))
req = urllib.request.Request('http://data.stats.gov.cn/easyquery.htm', d)
resp = urllib.request.urlopen(req)
print(resp.read())

4. 构造headers
import urllib.parse  
import urllib.request  
url = ''  
user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'  
headers = { 'User-Agent' : user_agent }  
req = urllib.request.Request(url)  
req.add_header('Referer', 'http://www.python.org/')  
response = urllib.request.urlopen(req)  
the_page = response.read()  
print(the_page.decode("utf8"))  

5. 使用代理
import urllib.request  
proxy_support = urllib.request.ProxyHandler({'sock5': 'localhost:1080'})  
opener = urllib.request.build_opener(proxy_support)  
urllib.request.install_opener(opener)  
a = urllib.request.urlopen("").read().decode("utf8")  
print(a)  

6. 异常处理
from urllib.request import Request, urlopen  
from urllib.error import URLError, HTTPError  
req = Request("http://www..net /")  
try:  
    response = urlopen(req)  
except HTTPError as e:  
    print('The server couldn't fulfill the request.')  
    print('Error code: ', e.code)  
except URLError as e:  
    print('We failed to reach a server.')  
    print('Reason: ', e.reason)  
else:  
    print("good!")  
    print(response.read().decode("utf8"))  
